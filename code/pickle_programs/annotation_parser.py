# File to take in a csv configuration file and output the image annotations to a file
# This program was used to take bounding rect annotations from a csv file, generated by using via 2.0.8 on hand sign images we created ourselves
# This information was going to be used to train Mask RCNN, a pretrained model used to predict bounding rectangles around features
# This model would have been used to extract hand signs from a larger image in order to increase the models ability to predict the signs in those images
# However, due to the lack of time, the MASk RCNN was never implemented and trained
# Hence, this file has no use

import sys, os, csv

def get_bounding_rect(filename):
    # Image size is (3000, 3000)
    unparsed_info = {}
    with open(filename, newline='') as csvfile:
        config_reader = csv.DictReader(csvfile)
        for row in config_reader:
            unparsed_info[row['filename'].split(".")[0]] = row['region_shape_attributes']
    
    # Now have a dictionary mapping filenames to unparsed bounding rectangle info
    parsed_info = {}
    for key in unparsed_info:
        value = unparsed_info[key].strip("{").strip("}")                # need to parse info
        formatted = " ".join((" ".join(value.split(":"))).split(","))   # Numbers wanted are surrounded by colons and commas, result is a string with the integer values seperated by spaces
        rect_values = formatted.split()[3:]
        x, y, width, height = int(rect_values[0]), int(rect_values[2]), int(rect_values[4]), int(rect_values[6])
        parsed_info[key] = (x, y, width, height)

    # Now create annotation files for each image
    for key in parsed_info:
        with open(key + ".txt", 'w') as f:
            xmin, ymin, rect_width, rect_height = parsed_info[key] # Top left x and y, then width and height of bounding rect
            
            width = 150  # Resize these images to make model run faster --> need to change annotation data as was compiled on (3000, 3000) images
            height = 150 # this info is known from the small dataset as the images were took by ourselves
            
            xmin, ymin, rect_width, rect_height = int((xmin/3000)*150), int((ymin/3000)*150), int((rect_width/3000)*150), int((rect_height/3000)*150) # (3000, 3000) --> (150, 150) images

            # (xmin, ymin) was top left to bottom left
            # (xmax, ymax) goes top right
            ymax = ymin
            ymin = ymin + rect_height
            xmax = xmin + rect_width

            # Formatting and writing to a file
            lst = str(" ".join([str(xmin), str(ymin), str(xmax), str(ymax)]))
            f.write(lst + " " + str(width) + " " + str(height))     # xmin, ymin, xmax, ymax, width, height

def main():
    # Only ran locally on my machine as I created the annotations
    DATADIR = "C:\\Users\\Bill\\3D Objects\\cnn_datasets\\hand_recognition_data\\annotations"
    os.chdir(DATADIR)
    get_bounding_rect("46_csv.csv")

if __name__ == '__main__':
    main()
